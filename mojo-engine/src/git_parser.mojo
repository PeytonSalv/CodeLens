"""Git log parser â€” shells out to git and parses delimited output into CommitData list.

Ports the git log parsing from scan.rs:29-98 including:
- Git log format: %H%x01%an%x01%ae%x01%aI%x01%s%x01%b%x00
- Claude Code detection (co-author markers)
- Change type classification (keyword matching)
- 4-hour time window feature clustering
"""

from .types import CommitData, FileChange, FeatureCluster
from .types.commit import _json_str



fn parse_git_log(repo_path: String) raises -> List[CommitData]:
    """Parse git log output into a list of CommitData.

    Runs: git log --format=%H%x01%an%x01%ae%x01%aI%x01%s%x01%b%x00 --no-merges
    """
    from python import Python

    var subprocess = Python.import_module("subprocess")
    var builtins = Python.import_module("builtins")
    var cmd = builtins.list()
    cmd.append("git")
    cmd.append("log")
    cmd.append("--format=%H%x01%an%x01%ae%x01%aI%x01%s%x01%b%x00")
    cmd.append("--no-merges")
    var result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        cwd=String(repo_path),
    )

    if Int(py=result.returncode) != 0:
        raise Error("git log failed: " + String(result.stderr))

    var log_str = String(result.stdout)
    var commits = List[CommitData]()

    # Split on null byte delimiter
    var entries = log_str.split("\x00")
    for ei in range(len(entries)):
        var entry_raw = String(entries[ei])
        var entry = String(entry_raw.strip())
        if entry == "":
            continue

        # Split on SOH delimiter, max 6 fields
        var fields = entry.split("\x01")
        if len(fields) < 5:
            continue

        var commit = CommitData()
        commit.hash = String(fields[0])
        commit.author_name = String(fields[1])
        commit.author_email = String(fields[2])
        commit.timestamp = String(fields[3])
        commit.subject = String(fields[4])
        if len(fields) > 5:
            commit.body = String(fields[5])
        else:
            commit.body = String("")

        # Detect Claude Code by co-author markers (scan.rs:72-75)
        var body_lower = commit.body.lower()
        commit.is_claude_code = (
            "co-authored-by: claude" in body_lower
            or "generated by claude" in body_lower
            or "claude" in commit.author_name.lower()
        )

        # Classify change type from commit subject (scan.rs:150-168)
        var lower_subject = commit.subject.lower()
        commit.change_type = classify_change_type(lower_subject)
        commit.change_type_confidence = 0.7

        commits.append(commit^)

    return commits^


fn classify_change_type(subject: String) -> String:
    """Classify commit change type from subject line keywords.

    Port of scan.rs:150-168 classify_change_type().
    """
    if subject.startswith("feat") or "add " in subject or "implement" in subject:
        return String("new_feature")
    elif subject.startswith("fix") or "bug" in subject or "patch" in subject:
        return String("bug_fix")
    elif "refactor" in subject or "restructure" in subject or "reorganiz" in subject:
        return String("refactor")
    elif "perf" in subject or "optimi" in subject or "speed" in subject:
        return String("performance")
    elif "test" in subject or "spec" in subject:
        return String("test")
    elif "doc" in subject or "readme" in subject or "comment" in subject:
        return String("documentation")
    elif "style" in subject or "format" in subject or "lint" in subject:
        return String("style")
    else:
        return String("new_feature")


fn parse_timestamp_epoch(ts: String) raises -> Int:
    """Parse ISO 8601 timestamp to epoch seconds using Python dateutil."""
    from python import Python

    var datetime = Python.import_module("datetime")
    var builtins = Python.import_module("builtins")

    try:
        var dt = datetime.datetime.fromisoformat(String(ts))
        var epoch = datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)
        var delta = dt - epoch
        return Int(py=delta.total_seconds())
    except:
        return 0


fn sort_commits_by_timestamp(mut commits: List[CommitData]) raises:
    """Sort commits by timestamp (newest first) using simple insertion sort."""
    from python import Python

    var datetime = Python.import_module("datetime")
    var builtins = Python.import_module("builtins")

    # Build epoch list for sorting
    var epochs = List[Int]()
    for i in range(len(commits)):
        try:
            var dt = datetime.datetime.fromisoformat(String(commits[i].timestamp))
            var epoch = datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)
            var delta = dt - epoch
            epochs.append(Int(py=delta.total_seconds()))
        except:
            epochs.append(0)

    # Simple selection sort (newest first = descending)
    for i in range(len(commits)):
        var max_idx = i
        for j in range(i + 1, len(commits)):
            if epochs[j] > epochs[max_idx]:
                max_idx = j
        if max_idx != i:
            # Swap in both lists
            commits.swap_elements(i, max_idx)
            var tmp_epoch = epochs[i]
            epochs[i] = epochs[max_idx]
            epochs[max_idx] = tmp_epoch


fn group_into_features(mut commits: List[CommitData]) raises -> List[FeatureCluster]:
    """Group commits into features using 4-hour time window.

    Port of scan.rs:205-249 group_into_features().
    Sorts commits oldest-first, then groups by time gaps > 4 hours.
    """
    if len(commits) == 0:
        return List[FeatureCluster]()

    from python import Python

    var datetime = Python.import_module("datetime")
    var builtins = Python.import_module("builtins")

    # Build epoch times for all commits
    var epochs = List[Int]()
    for i in range(len(commits)):
        try:
            var dt = datetime.datetime.fromisoformat(String(commits[i].timestamp))
            var epoch_ref = datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)
            var delta = dt - epoch_ref
            epochs.append(Int(py=delta.total_seconds()))
        except:
            epochs.append(0)

    # Build index array sorted by timestamp ascending (oldest first)
    var indices = List[Int]()
    for i in range(len(commits)):
        indices.append(i)

    # Selection sort by epoch ascending
    for i in range(len(indices)):
        var min_idx = i
        for j in range(i + 1, len(indices)):
            if epochs[indices[j]] < epochs[indices[min_idx]]:
                min_idx = j
        if min_idx != i:
            var tmp = indices[i]
            indices[i] = indices[min_idx]
            indices[min_idx] = tmp

    var four_hours: Int = 4 * 60 * 60
    var features = List[FeatureCluster]()
    var cluster_id: Int32 = 0
    var cluster_indices = List[Int]()
    cluster_indices.append(indices[0])

    for i in range(1, len(indices)):
        var prev_epoch = epochs[indices[i - 1]]
        var curr_epoch = epochs[indices[i]]
        var gap = curr_epoch - prev_epoch

        if gap > four_hours:
            # Finalize current cluster
            var feature = build_feature(cluster_id, cluster_indices, commits)
            # Assign cluster_id to commits
            for ci in range(len(cluster_indices)):
                commits[cluster_indices[ci]].cluster_id = cluster_id
            features.append(feature^)
            cluster_id += 1
            cluster_indices = List[Int]()

        cluster_indices.append(indices[i])

    # Finalize last cluster
    if len(cluster_indices) > 0:
        var feature = build_feature(cluster_id, cluster_indices, commits)
        for ci in range(len(cluster_indices)):
            commits[cluster_indices[ci]].cluster_id = cluster_id
        features.append(feature^)

    return features^


fn build_feature(
    cluster_id: Int32,
    indices: List[Int],
    commits: List[CommitData],
) -> FeatureCluster:
    """Build a FeatureCluster from a group of commit indices.

    Port of scan.rs:251-325 build_feature().
    """
    var feature = FeatureCluster()
    feature.cluster_id = cluster_id

    var total_added: UInt32 = 0
    var total_removed: UInt32 = 0

    # Track file frequencies using parallel lists (simple map)
    var file_paths = List[String]()
    var file_counts = List[Int]()

    for i in range(len(indices)):
        var idx = indices[i]
        feature.commit_hashes.append(commits[idx].hash)

        if i == 0:
            feature.time_start = commits[idx].timestamp
        feature.time_end = commits[idx].timestamp

        feature.add_change_type(commits[idx].change_type, 1)

        for fi in range(len(commits[idx].files_changed)):
            total_added += commits[idx].files_changed[fi].lines_added
            total_removed += commits[idx].files_changed[fi].lines_removed

            # Track file frequency
            var found = False
            for pi in range(len(file_paths)):
                if file_paths[pi] == commits[idx].files_changed[fi].path:
                    file_counts[pi] += 1
                    found = True
                    break
            if not found:
                file_paths.append(commits[idx].files_changed[fi].path)
                file_counts.append(1)

            for fi2 in range(len(commits[idx].files_changed[fi].functions)):
                var func_name = commits[idx].files_changed[fi].functions[fi2].name
                var already_tracked = False
                for ft in range(len(feature.functions_touched)):
                    if feature.functions_touched[ft] == func_name:
                        already_tracked = True
                        break
                if not already_tracked:
                    feature.functions_touched.append(func_name)

    feature.total_lines_added = total_added
    feature.total_lines_removed = total_removed

    # Primary files sorted by frequency (top 10)
    # Simple selection sort descending on file_counts
    var sorted_file_indices = List[Int]()
    for i in range(len(file_paths)):
        sorted_file_indices.append(i)

    for i in range(len(sorted_file_indices)):
        var max_idx = i
        for j in range(i + 1, len(sorted_file_indices)):
            if file_counts[sorted_file_indices[j]] > file_counts[sorted_file_indices[max_idx]]:
                max_idx = j
        if max_idx != i:
            var tmp = sorted_file_indices[i]
            sorted_file_indices[i] = sorted_file_indices[max_idx]
            sorted_file_indices[max_idx] = tmp

    var count = min(10, len(sorted_file_indices))
    for i in range(count):
        feature.primary_files.append(file_paths[sorted_file_indices[i]])

    # Auto-label from first commit subject
    if len(indices) > 0:
        var first_subject = commits[indices[0]].subject
        if len(first_subject) > 60:
            feature.auto_label = String(first_subject[:57]) + "..."
        else:
            feature.auto_label = first_subject
    else:
        feature.auto_label = "Feature #" + String(Int(cluster_id))

    return feature^


fn detect_languages(commits: List[CommitData]) -> List[String]:
    """Detect programming languages from file extensions.

    Port of scan.rs:603-652 detect_languages().
    """
    # Extension to language mapping
    var ext_keys = List[String]()
    var ext_langs = List[String]()
    ext_keys.append("rs"); ext_langs.append("Rust")
    ext_keys.append("ts"); ext_langs.append("TypeScript")
    ext_keys.append("tsx"); ext_langs.append("TypeScript")
    ext_keys.append("js"); ext_langs.append("JavaScript")
    ext_keys.append("jsx"); ext_langs.append("JavaScript")
    ext_keys.append("py"); ext_langs.append("Python")
    ext_keys.append("go"); ext_langs.append("Go")
    ext_keys.append("java"); ext_langs.append("Java")
    ext_keys.append("rb"); ext_langs.append("Ruby")
    ext_keys.append("cpp"); ext_langs.append("C++")
    ext_keys.append("c"); ext_langs.append("C")
    ext_keys.append("h"); ext_langs.append("C")
    ext_keys.append("cs"); ext_langs.append("C#")
    ext_keys.append("swift"); ext_langs.append("Swift")
    ext_keys.append("kt"); ext_langs.append("Kotlin")
    ext_keys.append("vue"); ext_langs.append("Vue")
    ext_keys.append("svelte"); ext_langs.append("Svelte")
    ext_keys.append("css"); ext_langs.append("CSS")
    ext_keys.append("scss"); ext_langs.append("CSS")
    ext_keys.append("html"); ext_langs.append("HTML")
    ext_keys.append("json"); ext_langs.append("JSON")
    ext_keys.append("toml"); ext_langs.append("TOML")
    ext_keys.append("yaml"); ext_langs.append("YAML")
    ext_keys.append("yml"); ext_langs.append("YAML")
    ext_keys.append("md"); ext_langs.append("Markdown")
    ext_keys.append("mojo"); ext_langs.append("Mojo")

    # Count extensions
    var lang_names = List[String]()
    var lang_counts = List[Int]()

    for ci in range(len(commits)):
        for fi in range(len(commits[ci].files_changed)):
            var path = commits[ci].files_changed[fi].path
            # Extract extension: find last '.'
            var ext = String("")
            var last_dot = -1
            for i in range(len(path)):
                if path.as_bytes()[i] == UInt8(ord(".")):
                    last_dot = i
            if last_dot >= 0 and last_dot < len(path) - 1:
                ext = String(path[last_dot + 1 :])

            if ext == "":
                continue

            # Map extension to language
            var lang = String("")
            for ei in range(len(ext_keys)):
                if ext_keys[ei] == ext:
                    lang = ext_langs[ei]
                    break
            if lang == "":
                continue

            # Accumulate
            var found = False
            for li in range(len(lang_names)):
                if lang_names[li] == lang:
                    lang_counts[li] += 1
                    found = True
                    break
            if not found:
                lang_names.append(lang)
                lang_counts.append(1)

    # Sort by count descending
    var sorted_indices = List[Int]()
    for i in range(len(lang_names)):
        sorted_indices.append(i)

    for i in range(len(sorted_indices)):
        var max_idx = i
        for j in range(i + 1, len(sorted_indices)):
            if lang_counts[sorted_indices[j]] > lang_counts[sorted_indices[max_idx]]:
                max_idx = j
        if max_idx != i:
            var tmp = sorted_indices[i]
            sorted_indices[i] = sorted_indices[max_idx]
            sorted_indices[max_idx] = tmp

    var result = List[String]()
    for i in range(len(sorted_indices)):
        result.append(lang_names[sorted_indices[i]])
    return result^


fn _shell_escape(s: String) -> String:
    """Escape a string for shell use (simple single-quote wrapper)."""
    return "'" + s + "'"

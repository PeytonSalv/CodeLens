use std::collections::HashMap;
use std::path::Path;
use std::process::Command;

use crate::types::{
    Analytics, CommitData, DateRange, FeatureCluster, FileChange, ProjectData, RepositoryInfo,
    WeekVelocity,
};

use super::sessions::parse_sessions_for_repo;

#[tauri::command]
pub async fn scan_repository(path: String) -> Result<ProjectData, String> {
    let repo_path = Path::new(&path);

    // Validate .git directory exists
    if !repo_path.join(".git").exists() {
        return Err(format!("Not a git repository: {}", path));
    }

    // Extract repo name from path
    let repo_name = repo_path
        .file_name()
        .and_then(|n| n.to_str())
        .unwrap_or("unknown")
        .to_string();

    // Run git log
    let log_output = Command::new("git")
        .args([
            "log",
            "--format=%H%x01%an%x01%ae%x01%aI%x01%s%x01%b%x00",
            "--no-merges",
        ])
        .current_dir(&path)
        .output()
        .map_err(|e| format!("Failed to run git log: {}", e))?;

    if !log_output.status.success() {
        return Err(format!(
            "git log failed: {}",
            String::from_utf8_lossy(&log_output.stderr)
        ));
    }

    let log_str = String::from_utf8_lossy(&log_output.stdout);
    let mut commits: Vec<CommitData> = Vec::new();

    for entry in log_str.split('\0') {
        let entry = entry.trim();
        if entry.is_empty() {
            continue;
        }

        let fields: Vec<&str> = entry.splitn(6, '\x01').collect();
        if fields.len() < 5 {
            continue;
        }

        let hash = fields[0].to_string();
        let author_name = fields[1].to_string();
        let author_email = fields[2].to_string();
        let timestamp = fields[3].to_string();
        let subject = fields[4].to_string();
        let body = if fields.len() > 5 {
            fields[5].to_string()
        } else {
            String::new()
        };

        // Detect Claude Code by co-author markers
        let is_claude_code = body.contains("Co-Authored-By: Claude")
            || body.contains("co-authored-by: Claude")
            || body.contains("Generated by Claude")
            || author_name.contains("Claude");

        // Classify change type from commit message keywords
        let lower_subject = subject.to_lowercase();
        let change_type = classify_change_type(&lower_subject);

        // Get file stats via git diff-tree
        let files_changed = get_file_stats(&path, &hash);

        commits.push(CommitData {
            hash,
            author_name,
            author_email,
            timestamp,
            subject,
            body,
            is_claude_code,
            session_id: None,
            change_type,
            change_type_confidence: 0.7,
            cluster_id: -1, // assigned during feature grouping
            files_changed,
        });
    }

    // Sort commits by timestamp (newest first)
    commits.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));

    // Group commits into features by 4-hour time window
    let mut features = group_into_features(&mut commits);

    // Compute analytics
    let analytics = compute_analytics(&commits, &features);

    // Build date range
    let date_range = if commits.is_empty() {
        DateRange {
            start: String::new(),
            end: String::new(),
        }
    } else {
        DateRange {
            start: commits.last().map(|c| c.timestamp.clone()).unwrap_or_default(),
            end: commits.first().map(|c| c.timestamp.clone()).unwrap_or_default(),
        }
    };

    let repository = RepositoryInfo {
        path: path.clone(),
        name: repo_name,
        total_commits: commits.len() as u32,
        date_range,
        languages_detected: detect_languages(&commits),
    };

    // Parse Claude Code session logs and correlate prompts to commits
    let mut prompt_sessions = parse_sessions_for_repo(&path);
    correlate_prompts_to_commits(&mut prompt_sessions, &commits);

    // Link prompts ↔ features bidirectionally and build sub-features
    link_prompts_to_features(&mut prompt_sessions, &commits, &mut features);

    // Update analytics with prompt count
    let mut analytics = analytics;
    analytics.total_prompts_detected = prompt_sessions.len() as u32;

    Ok(ProjectData {
        repository,
        commits,
        features,
        prompt_sessions,
        analytics,
    })
}

fn classify_change_type(subject: &str) -> String {
    if subject.starts_with("feat") || subject.contains("add ") || subject.contains("implement") {
        "new_feature".to_string()
    } else if subject.starts_with("fix") || subject.contains("bug") || subject.contains("patch") {
        "bug_fix".to_string()
    } else if subject.contains("refactor") || subject.contains("restructure") || subject.contains("reorganiz") {
        "refactor".to_string()
    } else if subject.contains("perf") || subject.contains("optimi") || subject.contains("speed") {
        "performance".to_string()
    } else if subject.contains("test") || subject.contains("spec") {
        "test".to_string()
    } else if subject.contains("doc") || subject.contains("readme") || subject.contains("comment") {
        "documentation".to_string()
    } else if subject.contains("style") || subject.contains("format") || subject.contains("lint") {
        "style".to_string()
    } else {
        "new_feature".to_string()
    }
}

fn get_file_stats(repo_path: &str, hash: &str) -> Vec<FileChange> {
    let output = Command::new("git")
        .args(["diff-tree", "--numstat", "--no-commit-id", "-r", hash])
        .current_dir(repo_path)
        .output();

    let output = match output {
        Ok(o) if o.status.success() => o,
        _ => return vec![],
    };

    let stdout = String::from_utf8_lossy(&output.stdout);
    let mut files = Vec::new();

    for line in stdout.lines() {
        let parts: Vec<&str> = line.split('\t').collect();
        if parts.len() < 3 {
            continue;
        }

        let lines_added = parts[0].parse::<u32>().unwrap_or(0);
        let lines_removed = parts[1].parse::<u32>().unwrap_or(0);
        let file_path = parts[2].to_string();

        files.push(FileChange {
            path: file_path,
            lines_added,
            lines_removed,
            functions: vec![], // function-level parsing skipped for now
        });
    }

    files
}

fn group_into_features(commits: &mut Vec<CommitData>) -> Vec<FeatureCluster> {
    if commits.is_empty() {
        return vec![];
    }

    // Sort oldest first for grouping
    let mut sorted: Vec<&mut CommitData> = commits.iter_mut().collect();
    sorted.sort_by(|a, b| a.timestamp.cmp(&b.timestamp));

    let mut features: Vec<FeatureCluster> = Vec::new();
    let mut current_cluster_id: i32 = 0;
    let mut cluster_commits: Vec<usize> = vec![0]; // indices into sorted
    let four_hours_secs: i64 = 4 * 60 * 60;

    for i in 1..sorted.len() {
        let prev_time = parse_timestamp(&sorted[i - 1].timestamp);
        let curr_time = parse_timestamp(&sorted[i].timestamp);

        let gap = curr_time - prev_time;

        if gap > four_hours_secs {
            // Finalize current cluster
            let feature = build_feature(current_cluster_id, &cluster_commits, &sorted);
            for &idx in &cluster_commits {
                sorted[idx].cluster_id = current_cluster_id;
            }
            features.push(feature);
            current_cluster_id += 1;
            cluster_commits = vec![i];
        } else {
            cluster_commits.push(i);
        }
    }

    // Finalize last cluster
    if !cluster_commits.is_empty() {
        let feature = build_feature(current_cluster_id, &cluster_commits, &sorted);
        for &idx in &cluster_commits {
            sorted[idx].cluster_id = current_cluster_id;
        }
        features.push(feature);
    }

    features
}

fn build_feature(
    cluster_id: i32,
    indices: &[usize],
    commits: &[&mut CommitData],
) -> FeatureCluster {
    let mut commit_hashes = Vec::new();
    let mut total_lines_added: u32 = 0;
    let mut total_lines_removed: u32 = 0;
    let mut file_set: HashMap<String, u32> = HashMap::new();
    let mut functions_touched: Vec<String> = Vec::new();
    let mut change_type_dist: HashMap<String, u32> = HashMap::new();

    let mut time_start = String::new();
    let mut time_end = String::new();

    for (i, &idx) in indices.iter().enumerate() {
        let commit = &commits[idx];
        commit_hashes.push(commit.hash.clone());

        if i == 0 {
            time_start = commit.timestamp.clone();
        }
        time_end = commit.timestamp.clone();

        *change_type_dist.entry(commit.change_type.clone()).or_insert(0) += 1;

        for file in &commit.files_changed {
            total_lines_added += file.lines_added;
            total_lines_removed += file.lines_removed;
            *file_set.entry(file.path.clone()).or_insert(0) += 1;

            for func in &file.functions {
                if !functions_touched.contains(&func.name) {
                    functions_touched.push(func.name.clone());
                }
            }
        }
    }

    // Primary files sorted by frequency
    let mut primary_files: Vec<String> = file_set.keys().cloned().collect();
    primary_files.sort_by(|a, b| file_set[b].cmp(&file_set[a]));
    primary_files.truncate(10);

    // Auto-label from first commit subject
    let auto_label = if !indices.is_empty() {
        let first = &commits[indices[0]];
        if first.subject.len() > 60 {
            format!("{}...", &first.subject[..57])
        } else {
            first.subject.clone()
        }
    } else {
        format!("Feature #{}", cluster_id)
    };

    FeatureCluster {
        cluster_id,
        title: None,
        auto_label,
        narrative: None,
        intent: None,
        key_decisions: vec![],
        commit_hashes,
        time_start,
        time_end,
        functions_touched,
        total_lines_added,
        total_lines_removed,
        primary_files,
        change_type_distribution: change_type_dist,
        dependencies: vec![],
        sub_features: vec![], // populated during prompt-feature linking
    }
}

fn parse_timestamp(ts: &str) -> i64 {
    // Parse ISO 8601 timestamp to epoch seconds
    chrono::DateTime::parse_from_rfc3339(ts)
        .map(|dt| dt.timestamp())
        .unwrap_or(0)
}

fn compute_analytics(commits: &[CommitData], features: &[FeatureCluster]) -> Analytics {
    let mut file_counts: HashMap<String, u32> = HashMap::new();
    let mut function_counts: HashMap<String, u32> = HashMap::new();
    let mut change_type_totals: HashMap<String, u32> = HashMap::new();
    let mut claude_count: u32 = 0;

    for commit in commits {
        *change_type_totals
            .entry(commit.change_type.clone())
            .or_insert(0) += 1;

        if commit.is_claude_code {
            claude_count += 1;
        }

        for file in &commit.files_changed {
            *file_counts.entry(file.path.clone()).or_insert(0) += 1;
            for func in &file.functions {
                *function_counts.entry(func.name.clone()).or_insert(0) += 1;
            }
        }
    }

    let total = commits.len() as f32;
    let claude_pct = if total > 0.0 {
        claude_count as f32 / total
    } else {
        0.0
    };

    // Sort files by count descending
    let mut most_modified_files: Vec<(String, u32)> = file_counts.into_iter().collect();
    most_modified_files.sort_by(|a, b| b.1.cmp(&a.1));
    let most_modified_files: Vec<String> = most_modified_files
        .into_iter()
        .take(10)
        .map(|(f, _)| f)
        .collect();

    let mut most_modified_functions: Vec<(String, u32)> = function_counts.into_iter().collect();
    most_modified_functions.sort_by(|a, b| b.1.cmp(&a.1));
    let most_modified_functions: Vec<String> = most_modified_functions
        .into_iter()
        .take(10)
        .map(|(f, _)| f)
        .collect();

    // Compute velocity by week
    let mut week_map: HashMap<String, (u32, u32)> = HashMap::new(); // (features, commits)
    for commit in commits {
        if let Ok(dt) = chrono::DateTime::parse_from_rfc3339(&commit.timestamp) {
            let week = dt.format("%G-W%V").to_string();
            let entry = week_map.entry(week).or_insert((0, 0));
            entry.1 += 1;
        }
    }
    for feature in features {
        if let Ok(dt) = chrono::DateTime::parse_from_rfc3339(&feature.time_start) {
            let week = dt.format("%G-W%V").to_string();
            let entry = week_map.entry(week).or_insert((0, 0));
            entry.0 += 1;
        }
    }
    let mut velocity_by_week: Vec<WeekVelocity> = week_map
        .into_iter()
        .map(|(week, (features, commits))| WeekVelocity {
            week,
            features,
            commits,
        })
        .collect();
    velocity_by_week.sort_by(|a, b| a.week.cmp(&b.week));

    Analytics {
        total_features: features.len() as u32,
        total_functions_modified: most_modified_functions.len() as u32,
        total_prompts_detected: 0,
        claude_code_commit_percentage: claude_pct,
        avg_prompt_similarity: 0.0,
        most_modified_files,
        most_modified_functions,
        change_type_totals,
        velocity_by_week,
    }
}

/// Link prompts to features bidirectionally and build sub-features.
/// For each prompt, find which features its associated commits belong to.
/// For each feature, build SubFeature entries from the prompts that contributed to it.
fn link_prompts_to_features(
    sessions: &mut [crate::types::PromptSession],
    commits: &[CommitData],
    features: &mut [crate::types::FeatureCluster],
) {
    use std::collections::HashSet;

    // Build a quick lookup: commit hash → cluster_id
    let commit_to_cluster: HashMap<&str, i32> = commits
        .iter()
        .map(|c| (c.hash.as_str(), c.cluster_id))
        .collect();

    // For each prompt, find its feature IDs via its associated commits
    for (prompt_idx, session) in sessions.iter_mut().enumerate() {
        let mut feature_ids: HashSet<i32> = HashSet::new();

        for hash in &session.associated_commit_hashes {
            if let Some(&cluster_id) = commit_to_cluster.get(hash.as_str()) {
                if cluster_id >= 0 {
                    feature_ids.insert(cluster_id);
                }
            }
        }

        let mut sorted_ids: Vec<i32> = feature_ids.into_iter().collect();
        sorted_ids.sort();
        session.associated_feature_ids = sorted_ids.clone();

        // For each feature this prompt is linked to, build a SubFeature
        for &feature_id in &sorted_ids {
            if let Some(feature) = features.iter_mut().find(|f| f.cluster_id == feature_id) {
                // Find which of this prompt's commits belong to this feature
                let feature_commit_set: HashSet<&str> =
                    feature.commit_hashes.iter().map(|h| h.as_str()).collect();

                let sub_commit_hashes: Vec<String> = session
                    .associated_commit_hashes
                    .iter()
                    .filter(|h| feature_commit_set.contains(h.as_str()))
                    .cloned()
                    .collect();

                // Compute lines added/removed from those commits
                let mut lines_added: u32 = 0;
                let mut lines_removed: u32 = 0;
                let mut sub_change_type = session
                    .prompt_text
                    .to_lowercase();

                for commit in commits {
                    if sub_commit_hashes.contains(&commit.hash) {
                        for file in &commit.files_changed {
                            lines_added += file.lines_added;
                            lines_removed += file.lines_removed;
                        }
                        // Use the first commit's change type
                        sub_change_type = commit.change_type.clone();
                    }
                }

                // Truncate prompt text for sub-feature label
                let prompt_label = if session.prompt_text.len() > 120 {
                    format!("{}...", &session.prompt_text[..117])
                } else {
                    session.prompt_text.clone()
                };

                feature
                    .sub_features
                    .push(crate::types::SubFeature {
                        prompt_text: prompt_label,
                        session_id: session.session_id.clone(),
                        prompt_index: prompt_idx as u32,
                        timestamp: session.timestamp.clone(),
                        time_end: session.time_end.clone(),
                        commit_hashes: sub_commit_hashes,
                        files_written: session.files_written.clone(),
                        lines_added,
                        lines_removed,
                        change_type: sub_change_type,
                        model: session.model.clone(),
                    });
            }
        }
    }

    // Sort sub-features within each feature by timestamp
    for feature in features.iter_mut() {
        feature
            .sub_features
            .sort_by(|a, b| a.timestamp.cmp(&b.timestamp));
    }
}

/// Correlate prompt sessions to commits by timestamp overlap and file intersection.
fn correlate_prompts_to_commits(
    sessions: &mut [crate::types::PromptSession],
    commits: &[CommitData],
) {
    use std::collections::HashSet;

    let five_min_secs: i64 = 5 * 60;

    for session in sessions.iter_mut() {
        let session_start = parse_timestamp(&session.timestamp);
        let session_end = session
            .time_end
            .as_deref()
            .map(|t| parse_timestamp(t))
            .unwrap_or(session_start);

        let session_files: HashSet<&str> = session
            .files_written
            .iter()
            .map(|f| f.as_str())
            .collect();

        for commit in commits {
            if !commit.is_claude_code {
                continue;
            }

            let commit_ts = parse_timestamp(&commit.timestamp);

            // Check timestamp overlap: commit falls within session window + 5 min buffer
            let in_time_window =
                commit_ts >= session_start && commit_ts <= session_end + five_min_secs;

            if !in_time_window {
                continue;
            }

            // Check file overlap
            let commit_files: HashSet<&str> = commit
                .files_changed
                .iter()
                .map(|f| f.path.as_str())
                .collect();

            // For file matching, compare just filenames since session paths are absolute
            // and commit paths are relative
            let session_filenames: HashSet<&str> = session_files
                .iter()
                .filter_map(|p| Path::new(p).file_name().and_then(|f| f.to_str()))
                .collect();

            let commit_filenames: HashSet<&str> = commit_files
                .iter()
                .filter_map(|p| Path::new(p).file_name().and_then(|f| f.to_str()))
                .collect();

            let overlap = session_filenames.intersection(&commit_filenames).count();

            // Score: time overlap (0.5) + file overlap fraction (0.4) + claude marker (0.1)
            let file_score = if !commit_filenames.is_empty() {
                overlap as f32 / commit_filenames.len() as f32
            } else {
                0.0
            };

            let score = 0.5 + (file_score * 0.4) + 0.1; // always claude_code here

            if score >= 0.5 {
                if !session
                    .associated_commit_hashes
                    .contains(&commit.hash)
                {
                    session.associated_commit_hashes.push(commit.hash.clone());
                }
                // Update similarity score to max seen
                if score > session.similarity_score {
                    session.similarity_score = score;
                }
                session.scope_match = file_score;
            }
        }
    }
}

fn detect_languages(commits: &[CommitData]) -> Vec<String> {
    let mut ext_counts: HashMap<String, u32> = HashMap::new();

    for commit in commits {
        for file in &commit.files_changed {
            if let Some(ext) = Path::new(&file.path).extension().and_then(|e| e.to_str()) {
                *ext_counts.entry(ext.to_string()).or_insert(0) += 1;
            }
        }
    }

    let ext_to_lang: HashMap<&str, &str> = HashMap::from([
        ("rs", "Rust"),
        ("ts", "TypeScript"),
        ("tsx", "TypeScript"),
        ("js", "JavaScript"),
        ("jsx", "JavaScript"),
        ("py", "Python"),
        ("go", "Go"),
        ("java", "Java"),
        ("rb", "Ruby"),
        ("cpp", "C++"),
        ("c", "C"),
        ("h", "C"),
        ("cs", "C#"),
        ("swift", "Swift"),
        ("kt", "Kotlin"),
        ("vue", "Vue"),
        ("svelte", "Svelte"),
        ("css", "CSS"),
        ("scss", "CSS"),
        ("html", "HTML"),
        ("json", "JSON"),
        ("toml", "TOML"),
        ("yaml", "YAML"),
        ("yml", "YAML"),
        ("md", "Markdown"),
    ]);

    let mut lang_counts: HashMap<String, u32> = HashMap::new();
    for (ext, count) in &ext_counts {
        if let Some(lang) = ext_to_lang.get(ext.as_str()) {
            *lang_counts.entry(lang.to_string()).or_insert(0) += count;
        }
    }

    let mut langs: Vec<(String, u32)> = lang_counts.into_iter().collect();
    langs.sort_by(|a, b| b.1.cmp(&a.1));
    langs.into_iter().map(|(l, _)| l).collect()
}
